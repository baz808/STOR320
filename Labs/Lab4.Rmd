---
title: "Summer Lab 4"
author: "Sarah Bazari"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
# This is a good place to put libraries required for using the ggplot function
knitr::opts_chunk$set(echo = TRUE,warning=F)
options(scipen=999)
library(tidyverse)
library(Ecdat)
library(modelr)
library(broom)
```

# Lab 4a: Control Structures

## Introduction

The main purpose of this lab is to practice control structures in R:

- `if` and `else`: testing a condition and acting on it
- `for`: execute a loop a fixed number of times
- `while`: execute a loop while a condition is true
- `repeat`: execute an infinite loop (must break out of it to stop) â€¢ break: break the execution of a loop
- `next`: skip an iteration of a loop

You will need to modify the code chunks so that the code works within each of chunk (usually this means modifying anything in ALL CAPS). You will also need to modify the code outside the code chunk. When you get the desired result for each step, change `Eval=F` to `Eval=T` and knit the document to HTML to make sure it works. After you complete the lab, you should submit your HTML file of what you have completed to Sakai before the deadline.

## Part 1: Vector and Control Structures

### 1.1 (2 points) 

Write code that creates a vector `x` that contains `100` random observations from the standard normal distribution (this is the normal distribution with the mean equal to `0` and the variance equal to `1`). Print out only the first five random observations in this vector.

```{r eval=TRUE}
# making a vector x with 100 random standard normal values
x <- rnorm(100)
# printing first five observations
print(x[1:5])

```

### 1.2 (2 points) 

Write code that replaces the observations in the vector `x` that are greater than or equal to `0` with a string of characters `"non-negative"` and the observations that are smaller than `0` with a string of characters `"negative"`. Hint: try `ifelse()` funtion. Print out the first five values in this new version of `x`.

```{r eval=TRUE}
# replace values in x with "non-negative" or "negative"
x <- ifelse(x >= 0, "non-negative", "negative")
# pringtin first five values
print(x[1:5])

```

### 1.3 (2 points) 

Write `for`-Loop to count how many observations in the vector `x` are non-negative and how many observations are negative. (There are many easier ways to solve this problem. Use `for`-Loop or get 0 points. Use the `cat()` function to print out a sentence that states how many non-negative and negative obervations there are. For example, "The number of non-negative observations is 32".

```{r eval=TRUE}
# initialize count
non_neg_count <- 0
neg_count <- 0

# loop through x to count
for (val in x) {
  if (val == "non-negative") {
    non_neg_count <- non_neg_count + 1
  } else if (val == "negative") {
    neg_count <- neg_count + 1
  }
}

cat("The number of non-negative observations is", non_neg_count, "\n")
cat("The number of negative observations is", neg_count, "\n")
```

## Part 2: Matrix and Control Structures

### 2.1 (4 points) 

Create a $100000$ by $10$ matrix `A` with the numbers $1:1000000$. The first row of this matrix should be the numbers 1 to 10. The second row of this matrix should be the numbers 11 to 20. Create a `for`-loop that calculates the sum for each row of the matrix and save the results to a vector `sum_row` and print out the first five values of `sum_row`.

```{r,eval=T}
A = matrix(1:1000000, nrow = 100000, ncol = 10, byrow = TRUE)

# initialize vector for storing row sums
sum_row <- numeric(100000)

# calculate row sums using a for-loop
for (i in 1:nrow(A)) {
  sum_row[i] <- sum(A[i, ])
}

#printing first five row sums
print(sum_row[1:5])
```

Verify that your results are consistent with what you obtain with the built-in `rowSums` function. 
```{r,eval=T}
sum_row_rowSums = as.integer(rowSums(A))
sum_row_rowSums[1:5]
```

### 2.2 (4 points) 

Another common loop structure that is used is the `while` loop, which functions much like a `for` loop, but will only run as long as a test condition is `TRUE`. Modify your `for` loop from the previous exercise and make it into a `while` loop. Use the `identical()` function to check if the results from the `for` loop are the same as the results from `while` loop.

```{r}
# intitalize while loop version
sum_row_while <- numeric(100000)
i <- 1
while (i <= nrow(A)) {
  sum_row_while[i] <- sum(A[i, ])
  i <- i + 1
}

# checking  if results are identical
# should return True or False
identical(sum_row, sum_row_while)
```

## Part 3: Data Frame and Control Structures

### 3.1 (4 points) 

Write a `for` loop to compute the mean of every column in `mtcars` and save the results to a vector `col_mean`. Ignore missing values when taking the mean.

```{r eval = T}
# initialize a numeric vector for toring column means
col_mean <- numeric(ncol(mtcars))

# looping through each column idx
for (i in 1:ncol(mtcars)) {
  col_mean[i] <- mean(mtcars[[i]], na.rm = TRUE)
}

print(col_mean)
```

### 3.2 (2 points) 

Compute the number of unique values in each column of `iris` and print the results during a loop. Use the `cat()` function to print out the values in a sentence with the corresponding name of the variable. For example, "The number of unique values for Sepal.Length is 35".

```{r}
names(iris) #DO NOT CHANGE

# looping through each column of iris
for (i in 1:ncol(iris)) {
  unique_count <- length(unique(iris[[i]]))
  cat("The number of unique values for", names(iris)[i], "is", unique_count, "\n")
}
```

# Lab 4b: Modeling Basics

## Introduction

In this lab, you will build predictive models for board game ratings. The dataset below was scraped from [boardgamegeek.com](www.boardgamegeek.com) and contains information on the top 4,999 board games. Below, you will see a preview of the data

```{r}
bgg<-read.csv("bgg.csv")
bgg2=bgg[,c(4:13,15:20)]
head(bgg2)
```


## Board Game Analysis

### Q1 (1.5 Points)

There are 16 variables and we want to create some more. Create a new dataframe called $bgg3$ where you use the mutate function to create the following variables:

- *duration=2018-year+1*
- *vote.per.year=num_votes/duration*
- *own.per.year=owned/duration*
- *player.range=max_players-min_players*
- *log_vote=log(num_votes+1)*
- *log_own=log(owned+1)*
- *diff_rating=avg_rating-geek_rating*

```{r,eval=T}
library(dplyr)

bgg3 <- bgg2 %>%
  mutate(
    duration = 2018 - year + 1,
    vote.per.year = num_votes / duration,
    own.per.year = owned / duration,
    player.range = max_players - min_players,
    log_vote = log(num_votes + 1),
    log_own = log(owned + 1),
    diff_rating = avg_rating - geek_rating
  )

head(bgg3)
```

**Question:** In complete sentences, what is the purpose of adding 1 for the log transformed variables?

Taking the log of a number less than or equal to 0 is not a defined value in math. Some games might have 0 votes/owners, so adding one makes sure we are not computing the log of 0.

**Question:** In complete sentences, what is the purpose of adding 1 in the creation of the year variable?

The formula 2018 - year + 1 computes how many years have passed since the game was released, which is the release year itself. Adding 1 ensures that the games released in 2018 have a duration that is equal to 1 and not 0, again, so we are not running into undefined values like dividng by zero. 

### Q2 (2 Points)

We hypothesize the geek rating increases when the number of votes increases and/or the ownership increases. Create four scatter plots showing the association with geek_rating and the following variables:

- *num_votes*
- *owned*
- *log_vote*
- *log_own*


```{r,eval=T}
library(ggplot2)

# scatter: geek_rating vs num_votes
ggplot(bgg3, aes(x = num_votes, y = geek_rating)) +
  geom_point(alpha = 0.4) +
  labs(title = "Geek Rating vs Number of Votes")

# scatter: geek_rating vs owned
ggplot(bgg3, aes(x = owned, y = geek_rating)) +
  geom_point(alpha = 0.4) +
  labs(title = "Geek Rating vs Owned")

# scatter: geek_rating vs log_vote
ggplot(bgg3, aes(x = log_vote, y = geek_rating)) +
  geom_point(alpha = 0.4) +
  labs(title = "Geek Rating vs Log(Number of Votes)")

# scatter: geek_rating vs log_own
ggplot(bgg3, aes(x = log_own, y = geek_rating)) +
  geom_point(alpha = 0.4) +
  labs(title = "Geek Rating vs Log(Owned)")
```

**Question:** In complete sentences, describe how the relationship changes when you take the log of the independent variable.

When we use the raw variables (num_votes and owned), the scatter plots show a highly skewed distribution, where most points are clustered near the origin, and a few extreme values are present in the spread. This makes it difficult to interpret the overall pattern or trend in the data. After applying the log transformation (log_vote and log_own), the distribution becomes more evenly spread out and the relationship with geek_rating becomes more linear and easier to interpret. The log transformation helps to reduce skewness and the influence of outliers, making it clearer that games with more votes or more owners have higher ratings.



### Q3 (0.5 Points)

Randomly sample approximately 80\% of the data in `bgg3` for a training dataset and the remaining will act as a test set. Call the training dataset `train.bgg` and the testing dataset `test.bgg`.

```{r,eval=T}
set.seed(1000)

bgg4= bgg3 %>%
        mutate(Set = sample(c("Train", "Test"), size = n(), replace = TRUE, prob = c(0.8, 0.2)))

train.bgg<-filter(bgg4,Set=="Train")
test.bgg<-filter(bgg4,Set=="Test")
```



### Q4 (0.5 Points)

Now, we want to fit models to the training dataset. Use the `lm()` function to create 3 model objects in R called `lm1`, `lm2`, `lm3` based on the following linear models, respectively:

- $\textrm{geek_rating}=\beta_0+\beta_1 log(\textrm{num_votes})+\epsilon$
- $\textrm{geek_rating}=\beta_0+\beta_1 log(\textrm{owned})+\epsilon$
- $\textrm{geek_rating}=\beta_0+\beta_1 log(\textrm{owned})+ \beta_2 \textrm{vote.per.year}+ \beta_3 \textrm{weight} + \epsilon$

```{r,eval=T}
# geek_rating ~ log(num_votes)
lm1 = lm(geek_rating ~ log(num_votes + 1),,data=train.bgg)
# geek_rating ~ log(owned)
lm2 = lm(geek_rating ~ log(owned + 1),data=train.bgg)
# geek_rating ~ log(owned) + vote.per.year + weight
lm3 = lm(geek_rating ~ log(owned + 1) + vote.per.year + weight,,data=train.bgg)
```

### Q5 (1 Point)

Add predictions and residuals for all 3 models to the test set. Create a new data frame called `test.bgg2` and give all your predictions and residuals different names. Use the `str()` function to show these variables were created


```{r,eval=T}
test.bgg2 <- test.bgg %>%
  mutate(
    pred1 = predict(lm1, newdata = test.bgg),
    resid1 = geek_rating - pred1,
    pred2 = predict(lm2, newdata = test.bgg),
    resid2 = geek_rating - pred2,
    pred3 = predict(lm3, newdata = test.bgg),
    resid3 = geek_rating - pred3
  )

str(test.bgg2)
```


### Q6 (0.5 Points)

Create a function called `MAE.func()` that returns the mean absolute error based on a vector of the residuals and test your function on the vector called `test`.

Solution 1:
```{r,eval=T}
test=c(-5,-2,0,3,5)

MAE.func = function(resid_vec) {
  mean(abs(resid_vec))
}

# testing it with sample data
test <- c(-5, -2, 0, 3, 5)

# sjould return 3
MAE.func(test)
```

### Q7 (1 Point)

Use your function on the `test.bgg2` to calculate the out-of-sample MAE of all three models based on the associated residuals. Make sure you display the mean absolute error from these different models in your output.

```{r,eval=T}
mae1 <- MAE.func(test.bgg2$resid1)
mae2 <- MAE.func(test.bgg2$resid2)
mae3 <- MAE.func(test.bgg2$resid3)

cat("MAE for Model 1:", mae1, "\n")
cat("MAE for Model 2:", mae2, "\n")
cat("MAE for Model 3:", mae3, "\n")

```

**Question:** Which model does the best job at predicting the geek rating of these board games?

The model with the lowest MAE does the best at predicting geek_rating, which we based on the mean absolute error values. Model 3 has the lowest MAE, most likely due to using more predictors in the model creation. So, Model 3 is the most accurate. Aslo, we used both vote.per.year and weight in addition to log(owned), so the models predictiveperformance is improved. 

### Q8 (3 Points)

For the third model only, use 10-fold cross-validation and measure the out-of-sample mean absolute error. Print out the final cross-validated mean absolute error.

```{r,eval=T}
set.seed(1000)

# shuffle data and assign numbers to each fold (1 to 10)
train.bgg.cv <- train.bgg %>%
  mutate(Fold = sample(rep(1:10, length.out = n())))

# initializing a vector to store MAEs for each fold
fold_mae <- numeric(10)

# loop through 
for (k in 1:10) {
  # splitting into training and validation sets
  cv_train <- filter(train.bgg.cv, Fold != k)
  cv_valid <- filter(train.bgg.cv, Fold == k)
  
  # fit model on training 
  model_k <- lm(geek_rating ~ log(owned + 1) + vote.per.year + weight, data = cv_train)
  
  # predict on validation fold
  preds <- predict(model_k, newdata = cv_valid)
  residuals <- cv_valid$geek_rating - preds
  
  # compute and store MAE
  fold_mae[k] <- mean(abs(residuals))
}

# calculating cross-validated MAE
cv_mae <- mean(fold_mae)
print(setNames(cv_mae, "Cross-validated MAE:"))


# absolute difference
abs_diff <- abs(mae3 - cv_mae)
print(setNames(abs_diff, "Absolute Difference:"))

# round
print(round(abs_diff, 4))
```

**Question:** What is the absolute difference between the out-of-sample mean absolute error measured using a test set and the mean absolute error measured using cross validation? When you type your answer in complete sentences use inline R code to calculate the absolute difference and input it directly into your sentence.

The absolute difference between the out-of-sample mean absolute error measured using the test set and the mean absolute error measured is 0.0027. This suggests that the model performs consistently across both validation methods.
